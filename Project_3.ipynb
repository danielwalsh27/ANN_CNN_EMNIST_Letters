{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "opj_PdpElBgN"
   },
   "source": [
    "# CPSC 585 Artificial Neural Networks Project 3\n",
    "## Handwritten Character Recognition with a Convolutional Neural Network\n",
    "\n",
    "### Group Members: \n",
    "### Jeremy Rico; jjrico@csu.fullerton.edu\n",
    "### Daniel Walsh; danielwalsh27@csu.fullerton.edu\n",
    "### Haojie Pan; haojie@csu.fullerton.edu\n",
    "\n",
    "This program uses as a Convolutional Artifical Neural Network with one hidden layer to predict the identity of handwritten characters of all 26 letters of the english alphabet.\n",
    "\n",
    "Dataset: EMNIST Letters - contains 145,600 28x28px images of handwritten characters divided into 26 classes. The dataset is divided into 108,000 training samples, 20,800 validation samples, and 20,800 test samples. More information about the dataset can be found here: https://www.nist.gov/itl/products-and-services/emnist-dataset\n",
    "\n",
    "Our project utilizes the tf.keras module of TensorFlow to create, train, and test the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1lAiZSMwlBgQ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import dirname, join as pjoin\n",
    "from scipy import io as sio\n",
    "#from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "di4iq8n0lBgx"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# inorder to import datasets you must have tensorflow datasets \n",
    "# installed by running the dollowing command in the terminal:\n",
    "# pip install -q tensorflow tensorflow-datasets matplotlib\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "zxgVBk53lBhE",
    "outputId": "198202e2-0775-47b2-a1f8-82a028e6c800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104000 training samples\n",
      "20800 validation samples\n",
      "20800 test samples\n",
      "(20800, 28, 28, 1) (20800, 26)\n"
     ]
    }
   ],
   "source": [
    "# Define some vars we will use to construct the model\n",
    "num_classes = 26\n",
    "batch_size = 2000\n",
    "epochs = 5\n",
    "neurons = 1000\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "mat_contents = sio.loadmat('emnist-letters.mat')\n",
    "data = mat_contents['dataset']\n",
    "\n",
    "X_train = data['train'][0,0]['images'][0,0]\n",
    "y_train = data['train'][0,0]['labels'][0,0]\n",
    "X_test = data['test'][0,0]['images'][0,0]\n",
    "y_test = data['test'][0,0]['labels'][0,0]\n",
    "\n",
    "val_start = X_train.shape[0] - X_test.shape[0]\n",
    "X_val = X_train[val_start:X_train.shape[0],:]\n",
    "y_val = y_train[val_start:X_train.shape[0]]\n",
    "X_train = X_train[0:val_start,:]\n",
    "y_train = y_train[0:val_start]\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "y_train -= 1\n",
    "y_val -= 1\n",
    "y_test -= 1\n",
    "\n",
    "#convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(X_train.shape[0], \"training samples\")\n",
    "print(X_val.shape[0], \"validation samples\")\n",
    "print(X_test.shape[0], \"test samples\")\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "owKsngRwlBhV"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                        activation='relu',\n",
    "                        input_shape=input_shape))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 749
    },
    "colab_type": "code",
    "id": "Zx1467aClBhf",
    "outputId": "929481b8-2d7b-4451-97c5-7b86884ab51f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 104000 samples, validate on 20800 samples\n",
      "Epoch 1/5\n",
      "104000/104000 [==============================] - 87s 840us/sample - loss: 57.1850 - accuracy: 0.0388 - val_loss: 30.4661 - val_accuracy: 0.0476\n",
      "Epoch 2/5\n",
      "104000/104000 [==============================] - 92s 885us/sample - loss: 47.2778 - accuracy: 0.0419 - val_loss: 22.8767 - val_accuracy: 0.0508\n",
      "Epoch 3/5\n",
      "104000/104000 [==============================] - 101s 975us/sample - loss: 39.8488 - accuracy: 0.0448 - val_loss: 17.8242 - val_accuracy: 0.0571\n",
      "Epoch 4/5\n",
      "104000/104000 [==============================] - 102s 977us/sample - loss: 33.8591 - accuracy: 0.0481 - val_loss: 14.2599 - val_accuracy: 0.0642\n",
      "Epoch 5/5\n",
      "104000/104000 [==============================] - 101s 976us/sample - loss: 28.7136 - accuracy: 0.0520 - val_loss: 11.6106 - val_accuracy: 0.0752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x148ce1850>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size = batch_size,\n",
    "          epochs = epochs,\n",
    "          verbose = 1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "7GDm6TNZlBhs",
    "outputId": "51beb97e-31b2-402c-8189-62605db95a4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 11.521498832702637\n",
      "Test accuracy: 0.07894231\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NiACnYYjqovH"
   },
   "source": [
    "## Test Results\n",
    "\n",
    "| Epochs | Batch Size | Hidden Layer| Accuracy | Rows/Col  | Kernel Size | Pool Size |\n",
    "|--------|------------|-------------|----------|-----------|-------------|-----------|\n",
    "|5       |2000        |1000         |07.89%    | 28 x 28   |   3 x 3     |  2 x 2    | \n",
    "|        |            |             |          |           |             |           |\n",
    "|        |            |             |          |           |             |           |\n",
    "|        |            |             |          |           |             |           |\n",
    "|        |            |             |          |           |             |           |\n",
    "|        |            |             |          |           |             |           |\n",
    "|        |            |             |          |           |             |           |\n",
    "|        |            |             |          |           |             |           |\n",
    "|        |            |             |          |           |             |           |\n",
    "|        |            |             |          |           |             |           |\n",
    "|        |            |             |          |           |             |           |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project_3_take2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
